% Generated by roxygen2: do not edit by hand
% Please edit documentation in
%   R/longpye_kernel_smoothing_with_covariates_same_betas.R
\name{longpye_KS_same_betas}
\alias{longpye_KS_same_betas}
\title{longpye_KS_same_betas}
\usage{
longpye_KS_same_betas(
  df_train,
  df_test = NULL,
  id = "id",
  X = names(df_train[, !(names(df_train) \%in\% c(y, id, t))]),
  y = "y",
  t = "t",
  betas,
  lambda,
  c = rep(0, length(unique(df_train[, t]))),
  kernel = "gaussian",
  alpha = 0.5,
  a1 = 3.7,
  a2 = 3,
  penalty = "L1",
  h_exponent = 0.2,
  prediction = FALSE,
  print.CDF.plot = FALSE,
  c_hat_discriminant = NULL
)
}
\arguments{
\item{X}{regressors to consider in the estimation. It can be of type
dataframe, containing also the same name of the regressors included in df,
of just a vector of character. Default is all not present in y}

\item{y}{the target variable. It can be only binomial 0,1. It can be of type
dataframe, containing also the same name of the same target variable included
in df, or just a character. Default is "y".}

\item{t}{is the name of the variable that refers to the time in the input
dataset.}

\item{betas}{the coefficients of the biomarker combination used for the
evaluation of PYE}

\item{lambda}{the penalization parameter of the regressors X}

\item{c}{the cut-off points, a vector having the length of the times}

\item{kernel}{the kernel type to use for the estimation of the density
function (tested only for "gaussian").  Default is "gaussian"}

\item{alpha}{parameter for the Elastic-Net penalization term. Default is 0.5}

\item{a1}{parameter for the SCAD and MCP penalization term. Default is 3.7}

\item{a2}{parameter for the MCP penalization term. Default is 3.0}

\item{penalty}{the considered penalty. To be chosen among L12, L1, EN, SCAD
and MCP. Default is "L1"}

\item{h_exponent}{parameter of the bandwidth of the Kernel Smooth}

\item{prediction}{if TRUE the empirical maximum Youden index is returned as
Youden index performance measure}

\item{print.CDF.plot}{if TRUE it prints also the plot of the CDFs of cases
and controls for the compination of regressors Z for each dimension. Default
is FALSE}

\item{df}{the input dataset}
}
\value{
a list containing the value of PYE for the given penalty, the value
of the main accuracy measure and the gradient of PYE computer the the given
point.
}
\description{
The Penalizad Youden Index (PYE) function for longitudinal data
based on the Kernel Smooth density estimator. It not only evaluate PYE in
logitudinal case, but it returns all the necessary for the estimation
process, like measure of fit and derivatives. It works for all the
considered penalties (L12, L1, EN, SCAD and MCP)
}
\examples{
library(pye)
cols <- 2000
cols_cov <- 20
seed=1
simMicroarrayData_cov02_dim50_covariates <- create_sample_with_covariates(
		rows_train=50, cols=cols, cols_cov=cols_cov, covar=0.2, seed=seed)
df <- simMicroarrayData_cov02_dim50_covariates$train_df_scaled
X <- simMicroarrayData_cov02_dim50_covariates$X
y <- simMicroarrayData_cov02_dim50_covariates$y
C <- simMicroarrayData_cov02_dim50_covariates$C
penalty <- "L12"
lambda <- 0.1
betas <- rep(1, length(X))
c <- 0
prox_penalty <- get(paste0("proximal_operator_", penalty))

PYE_result <- pye_KS(df=df[,names(df) \%in\% c(X,y)], X=X, y=y, betas=betas,
  lambda=lambda, c=c, alpha=0.5, a1=3.7, a2=3, penalty=penalty)
print(PYE_result)

}
