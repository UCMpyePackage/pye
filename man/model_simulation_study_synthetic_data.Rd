% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/simulation_study_other_models_with_covariates.R
\name{model_simulation_study_synthetic_data}
\alias{model_simulation_study_synthetic_data}
\title{model_simulation_study_synthetic_data}
\usage{
model_simulation_study_synthetic_data(
  n = 1000,
  rows_train = 50,
  rows_test = 1000,
  cols = 2000,
  cols_cov = 20,
  covar = 0.5,
  mu = rep(0, cols),
  mu_cov = rep(0, cols_cov),
  model_estimation_function,
  model_prediction_function,
  model_type,
  lambda,
  tau = 0,
  trace = 2,
  alpha = 0.5,
  used_cores = 1,
  c_function_of_covariates = FALSE,
  alpha_g = 0.5,
  penalty_g = "L1",
  kernel_g = "gaussian",
  a1_g = 3.7,
  a2_g = 3,
  trend_g = "monotone",
  gamma_start_input = NULL,
  gamma_start_default = "zeros",
  max_iter_g = 10000,
  delta_g = 1e-05,
  max_alpha_g = 10000,
  stepsizeShrink_g = 0.8,
  min_alpha_g = 1e-12,
  convergence_error_g = 1e-07,
  run_aauc = FALSE
)
}
\arguments{
\item{n}{number of esperiments. Default is 1000}

\item{rows_train}{number of rows of the training sample. Default is 50,
for an high-dimensional setting}

\item{rows_test}{number of rows of the test sample. Default is 1000.
We suggest to create a test sample much bigger than the training sample
to test your method/model on more data}

\item{cols}{number of regressor variables of both the training and the
test samples. Default is 2000, for an high-dimensional setting}

\item{cols_cov}{number of covariate variables of both the training and the
test samples. Default is 20, increase it for an high-dimensional setting}

\item{covar}{covariance in the covariace matrix of the normal distribution.
Increasing it, the created features are more correlated. Default is 0.5}

\item{mu}{mean of the (multivariate) normal distribution of the regressors.
Default is 0}

\item{mu_cov}{mean of the (multivariate) normal distribution of the
covariates. Default is 0}

\item{model_estimation_function}{function to use for the estimation. The user
can choose among "glmnet_estimation", "all_svm_estimation", "AucPR_estimation"}

\item{model_prediction_function}{function to use for the prediction. The user
can choose among "glmnet_predict", "all_svm_predict", "AucPR_predict"}

\item{model_type}{model to use in the estimation. The user can choose
among "logLasso", "logElasticNet", "logSCAD", "logMCP", "SCADSVM",
"ElasticSCADSVM", "l1SVM", "enSVM", "AucPR_L1", "AucPR_EN"}

\item{lambda}{the penalization parameter of the regressors X}

\item{tau}{the penalization parameter of the covariates C, in covYI. Default 0,
i.e. no penalization term}

\item{trace}{2:visualize all the steps, 1:visualize just the result,
0:visualize nothing. Default is 1}

\item{alpha}{parameter for the Elastic-Net penalization term. Default is 0.5}

\item{used_cores}{number of core used for the parallelization of the
process. if equal to 1, then no parallelization is adopted. Default is 1.}

\item{c_function_of_covariates}{if TRUE, covYI is used to estimate the
cut-off point as function of the convariate information. If FALSE, the
covariate information is ignored. Default is FALSE}

\item{alpha_g}{parameter for the Elastic-Net penalization term in covYI.
Default is 0.5}

\item{penalty_g}{the considered penalty of covYI. To be chosen among L12, L1,
EN, SCAD and MCP. Default if "L1"}

\item{kernel_g}{the kernel type to use for the estimation of the density
function (tested only for "gaussian") in covYI.  Default is "gaussian"}

\item{a1_g}{parameter for the SCAD and MCP penalization term in covYI. Default is 3.7}

\item{a2_g}{parameter for the MCP penalization term in covYI. Default is 3.0}

\item{trend_g}{for covYI. If "monotone", mmAPG is used, if "nonmonotone",
mnmAPG is used. Default is "monotone"}

\item{gamma_start_input}{vector of a specific starting point for gammas.
Default is NULL, i.e. no input vector}

\item{gamma_start_default}{set the default starting point of gamma.
If "zeros", it starts with all zero values, if "corr" it starts with the
value of the correlation of every regressor with the target variable. Default
is "zeros"}

\item{max_iter_g}{maximum number of iterations in the algorithms mmAPG and
mnmAPG in covYI. Default is 500}

\item{delta_g}{parameter for the convergence condition of the optimization
algorithm of covYI. Default is 1e-5}

\item{max_alpha_g}{maximum value of the step-parameter alpha in covYI.
Default is 100}

\item{stepsizeShrink_g}{parameter to adjust the step-size in the backtracking
line-search, in the optimization of covYI. Taking values between 0 and 1,
the closer to 1, the more accurate the estimation will be, the longer it
will take and viceversa. Default is 0.8}

\item{min_alpha_g}{minimum value of the step-parameter alpha in covYI.
Default is 1e-12}

\item{convergence_error_g}{in covYI, it is error to accept for considering the algorithm
converged. Default is 1e-5}

\item{run_aauc}{if FALSE the aAUC and aYI are not computed, to save stimation
time if not requested. Default is FALSE}
}
\value{
a list containing the classification measure related to every simulation.
}
\description{
function to perform the simulation on n different
experiments, for all the considered methods competitor of pye
for simulated data.
In every iteration we start creating a new synthetic dataset and
then we randomly split it in train and test, estimating the method in the
train and evaluating the classification measures on the test set.
}
\examples{
library(pye)
rows_train <- 50
rows_test <- 1000
cols <- 2000
cols_cov <- 20
covar <- 0.5
mu <- rep(0,cols)
mu_cov <- rep(0,cols_cov)
pye_starting_point <- "zeros" #c("zeros", "corr")
alpha <- 0.5
used_cores <- 1
n<- 5 #number of simulations
c_function_of_covariates <- TRUE

used_penalty_covYI <- c("L12", "L1") #c("L12", "L1", "EN", "SCAD", "MCP")
for (p in used_penalty_covYI){

  #--------------------------------------------------------------------------
  #                                  START                                  |
  #--------------------------------------------------------------------------
  other_models_vector = c("logLasso", "SCADSVM", "AucPR_L1")
			 # c("logLasso","logElasticNet", "logSCAD", "logMCP",
          # "SCADSVM", "ElasticSCADSVM", "l1SVM", "enSVM",
          # "AucPR_L1", "AucPR_EN")

  functions <- c("glmnet", "all_svm", "AucPR")

  measures <- c("ccr") #c("auc", "aauc", "aYI", "ccr", "yi", "gm")
  for (m in other_models_vector){
    if (m \%in\% c("logLasso", "logElasticNet", "logSCAD", "logMCP")){f <- functions[1]}
    if (m \%in\% c("SVM_linear", "SVM_polynomial", "SVM_radial", "SVM_sigmoid", "SCADSVM",
					"ElasticSCADSVM", "l1SVM", "enSVM")){f <- functions[2]}
    if (m \%in\% c("AucPR_L1", "AucPR_EN")){f <- functions[3]}
    for (mm in 1:length(measures)){
 	  cat("---> Starting with measure", measures[mm],
				", for the covYI penalty", p, "<---\n")
 	  name_est <- get(paste0(f ,"_estimation"))
 	  name_pred <- get(paste0(f ,"_predict"))
 	  name <- paste0(m, "_covYI_", p, "_sim_study_" , measures[mm])
 	  lambda_to_use <- 0.1
 	  tau_to_use <- 0.05
 	  assign(name, model_simulation_study_synthetic_data(n=n, rows_train=rows_train,
							   rows_test=rows_test,  cols=cols,
							   cols_cov=cols_cov, covar=covar,
							   mu=mu, mu_cov=mu_cov,
							   model_estimation_function=name_est,
							   model_prediction_function=name_pred,
							   model_type=m,
 	                           lambda=lambda_to_use,
 	                           tau=tau_to_use,
 	                           gamma_start_default=pye_starting_point,
 	                           trace=1,
 	                           alpha=alpha, alpha_g=alpha,
 	                           a1_g=3.7, a2_g=3.7, penalty_g=p,
 	                           used_cores=used_cores,
 	                           c_function_of_covariates=c_function_of_covariates,
								   run_aauc=FALSE, max_iter_g=10))
 	 }
  }
}
cat("Computation finished! Start saving data.")
print(name)

}
