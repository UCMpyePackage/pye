% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cPYE_kernel_smoothing_function.R
\name{cPYE_KS_compute_cv}
\alias{cPYE_KS_compute_cv}
\title{cPYE_KS_compute_cv}
\usage{
cPYE_KS_compute_cv(
  n_folds,
  df,
  X = names(df[, !(names(df) \%in\% c(y, C))]),
  y = "y",
  C,
  lambda,
  tau,
  trace = 2,
  alpha = 0.5,
  a1 = 3.7,
  a2 = 3,
  penalty = "L1",
  regressors_betas = NULL,
  regressors_gammas = NULL,
  seed = 1,
  used_cores = 1,
  trend = "monotone",
  delta = 1e-05,
  max_iter = 10000,
  max_alpha = 10000,
  min_alpha = 1e-10,
  convergence_error = 1e-07,
  stepsizeShrink = 0.8,
  kernel = "gaussian",
  beta_start_input = NULL,
  beta_start_default = "zeros",
  gamma_start_input = NULL,
  gamma_start_default = "zeros",
  scaling = FALSE,
  run_aauc = FALSE
)
}
\arguments{
\item{n_folds}{number of fold of the cross validation}

\item{df}{the input dataset}

\item{X}{regressors to consider in the estimation. It can be of type
dataframe, containing also the same name of the regressors included in df,
of just a vector of character. Default is all not present in y and C}

\item{y}{the target variable. It can be only binomial 0,1. It can be of type
dataframe, containing also the same name of the same target variable included
in df, or just a character. Default is "y".}

\item{C}{covariate variables. It can be of type dataframe, containing the
same covariates included in df, or just a vector of character.}

\item{lambda}{the penalization parameter of the regressors X}

\item{tau}{the penalization parameter of the covariates C, in covYI. Default 0,
i.e. no penalization term}

\item{trace}{2:visualize all the steps, 1:visualize just the result,
0:visualize nothing. Default is 1}

\item{alpha}{parameter for the Elastic-Net penalization term. Default is 0.5}

\item{a1}{parameter for the SCAD and MCP penalization term. Default is 3.7}

\item{a2}{parameter for the MCP penalization term. Default is 3.0}

\item{penalty}{the considered penalty. To be chosen among L12, L1, EN, SCAD
and MCP. Default is "L1"}

\item{regressors_betas}{a vector containing the real betas (if known). Default
is NULL, i.e. we do not know the real regressors}

\item{regressors_gammas}{a vector containing the real gammas (if known).
Default is NULL}

\item{seed}{fix the seed. Default is 1}

\item{used_cores}{number of core used for the parallelization of the
process. if equal to 1, then no parallelization is adopted. Default is 1.}

\item{trend}{if "monotone", mmAPG is used, if "nonmonotone", mnmAPG is used.
Default is "monotone"}

\item{delta}{parameter for the convergence condition of the optimization
algorithm. Default is 1e-5}

\item{max_iter}{maximum number of iterations in the algorithms mmAPG and
mnmAPG. Default is 10000}

\item{max_alpha}{maximum value of the step-parameter alpha. Default is 1000}

\item{min_alpha}{minimum value of the step-parameter alpha. Default is 1e-12}

\item{convergence_error}{error to accept for considering the algorithm
converged. Default is 1e-5}

\item{stepsizeShrink}{parameter to adjust the step-size in the backtracking
line-search, in the optimization of pye. Taking values between 0 and 1,
the closer to 1, the more accurate the estimation will be, the longer it
will take and viceversa. Default is 0.8}

\item{kernel}{the kernel type to use for the estimation of the density
function (tested only for "gaussian").  Default is "gaussian"}

\item{beta_start_input}{vector of a specific starting point for betas.
Default is NULL, i.e. no input vector}

\item{beta_start_default}{set the default starting point of betas. If "zeros", it
starts with all zero values, if "corr" it starts with the value of the
correlation of every regressor with the target variable. Default is "zeros"}

\item{gamma_start_input}{vector of a specific starting point for gammas.
Default is NULL, i.e. no input vector}

\item{gamma_start_default}{set the default starting point for gammas. If "zeros", it
starts with all zero values, if "corr" it starts with the value of the
correlation of every regressor with the target variable. Default is "zeros"}

\item{scaling}{if TRUE, the dataset is scaled. FALSE otherwise, Default is
FALSE.}

\item{run_aauc}{if FALSE the aAUC and aYI are not computed, to save stimation
time if not requested. Default is FALSE}
}
\value{
a list containing the optimal value of lambda and tau to estimate betas and
c, the value of the main accuracy measure for all the folds.
}
\description{
function to perform the cross-validation to select the best
value of lambda and tau for the estimation of betas and c using PYE.
}
\examples{
library(pye)
cols <- 2000
cols_cov <- 20
seed=1
simMicroarrayData_cov02_dim50_covariates <- create_sample_with_covariates(
		rows_train=50, cols=cols, cols_cov=cols_cov, covar=0.2, seed=seed)
df <- simMicroarrayData_cov02_dim50_covariates$train_df_scaled
X <- simMicroarrayData_cov02_dim50_covariates$X
y <- simMicroarrayData_cov02_dim50_covariates$y
C <- simMicroarrayData_cov02_dim50_covariates$C
regressors_betas<-simMicroarrayData_cov02_dim50_covariates$nregressors
regressors_gammas<-simMicroarrayData_cov02_dim50_covariates$ncovariates
penalty <- "SCAD"
betas <- rep(1, length(X))
c <- 0
prox_penalty <- get(paste0("proximal_operator_", penalty))
param_start_default <- "zeros"
alpha <- 0.5
tau_star <- 0.5 #a starting value of tau, to calibrate lambda
n_folds <- 3
used_cores <- 1
max_iter <- 5
used_penalty_cPYE <- c("L12", "SCAD") #c("L12", "L1", "EN", "SCAD", "MCP")

#cPYE Gaussian (and others) Kernel Smooth
for (p in used_penalty_cPYE){

  name <- paste0("lambda_estimate_cPYE_KS_", p)

  #wrapper of the function
  wrapper_lambda <- function(lambda){
    return(cPYE_KS_estimation(df=df, X=X, y=y, C=C, penalty=p, trace=2,
   beta_start_default=param_start_default,
    gamma_start_default=param_start_default, lambda=lambda, tau=tau_star,
    alpha=alpha, regressors_betas=regressors_betas,
    regressors_gammas=regressors_gammas, max_iter=max_iter, run_aauc=FALSE))
  }
  #lambda to max and min
  lambda_max <- calibrate_lambda_max (function_to_run=wrapper_lambda,
    var_to_check=paste0("betas_hat_",p), lambda_start = 5)
  lambda_min <- calibrate_lambda_min (function_to_run=wrapper_lambda,
    var_to_check=paste0("betas_hat_",p), lambda_start = 0.0001, max_var = 100)

  #create a suited lambda
  lambda <- create_lambda(n=3, lmax=lambda_max, lmin=lambda_min)
  lambda <- as.numeric(formatC(lambda, format = "e", digits = 9))

  #create a suited tau
 lambda_star <- (lambda_max+lambda_min)/2
  wrapper_tau <- function(tau){
    return(cPYE_KS_estimation(df=df, X=X, y=y, C=C, penalty=p, trace=2,
   beta_start_default=param_start_default,
    gamma_start_default=param_start_default, lambda=lambda_star, tau=tau,
    alpha=alpha, regressors_betas=regressors_betas,
    regressors_gammas=regressors_gammas, max_iter=max_iter, run_aauc=FALSE))
  }

 #tau to max and min
  tau_max <- calibrate_lambda_max (function_to_run=wrapper_tau,
    var_to_check=paste0("gammas_hat_",p), lambda_start = 5, n_min_var=1)
  tau_min <- calibrate_lambda_min (function_to_run=wrapper_tau,
    var_to_check=paste0("gammas_hat_",p), lambda_start = 0.0001, max_var= 50)

  #create a suited tau
  tau <- create_lambda(n=3, lmax=tau_max, lmin=tau_min)
  tau <- as.numeric(formatC(tau, format = "e", digits = 9))

  #start cross-validation
  assign(name, cPYE_KS_compute_cv(penalty=p, df=df, X=X, y=y, C=C, trace=2,
    beta_start_default=param_start_default,
    gamma_start_default=param_start_default, n_folds=n_folds, lambda=lambda,
    tau=tau, alpha=alpha, regressors_betas=regressors_betas,
    regressors_gammas=regressors_gammas, used_cores=used_cores,
    max_iter=max_iter))

  #take the best lambda per measures (with the same measure for diff lambdas,
  #we take the one associated to less betas)
  assign(paste0("lambda_hat_cPYE_KS_", p ,"_yi"), get(name)$lambda_hat_cPYE_KS_yi)
  assign(paste0("lambda_hat_cPYE_KS_", p ,"_auc"), get(name)$lambda_hat_cPYE_KS_auc)
  assign(paste0("lambda_hat_cPYE_KS_", p ,"_aauc"), get(name)$lambda_hat_cPYE_KS_aauc)
  assign(paste0("lambda_hat_cPYE_KS_", p ,"_aYI"), get(name)$lambda_hat_cPYE_KS_aYI)
  assign(paste0("lambda_hat_cPYE_KS_", p ,"_ccr"), get(name)$lambda_hat_cPYE_KS_ccr)
  assign(paste0("lambda_hat_cPYE_KS_", p ,"_gm"), get(name)$lambda_hat_cPYE_KS_gm)
  assign(paste0("lambda_hat_cPYE_KS_", p ,"_cPYE"), get(name)$lambda_hat_cPYE_KS_cPYE)

  assign(paste0("tau_hat_cPYE_KS_", p ,"_yi"), get(name)$tau_hat_cPYE_KS_yi)
  assign(paste0("tau_hat_cPYE_KS_", p ,"_auc"), get(name)$tau_hat_cPYE_KS_auc)
  assign(paste0("tau_hat_cPYE_KS_", p ,"_aauc"), get(name)$tau_hat_cPYE_KS_aauc)
  assign(paste0("tau_hat_cPYE_KS_", p ,"_aYI"), get(name)$tau_hat_cPYE_KS_aYI)
  assign(paste0("tau_hat_cPYE_KS_", p ,"_ccr"), get(name)$tau_hat_cPYE_KS_ccr)
  assign(paste0("tau_hat_cPYE_KS_", p ,"_gm"), get(name)$tau_hat_cPYE_KS_gm)
  assign(paste0("tau_hat_cPYE_KS_", p ,"_cPYE"), get(name)$tau_hat_cPYE_KS_cPYE)

}

}
