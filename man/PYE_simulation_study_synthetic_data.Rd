% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pye_simulation_study_with_covariates.R
\name{PYE_simulation_study_synthetic_data}
\alias{PYE_simulation_study_synthetic_data}
\title{PYE_simulation_study_synthetic_data}
\usage{
PYE_simulation_study_synthetic_data(
  n = 1000,
  rows_train = 50,
  rows_test = 1000,
  cols = 2000,
  cols_cov = 20,
  covar = 0.5,
  mu = rep(0, cols),
  mu_cov = rep(0, cols_cov),
  lambda,
  tau = 0,
  trace = 1,
  used_cores = 1,
  c_function_of_covariates = FALSE,
  c_zero_fixed = FALSE,
  beta_start_input = NULL,
  beta_start_default = "zeros",
  max_iter = 10000,
  trend = "monotone",
  delta = 1e-05,
  max_alpha = 10000,
  stepsizeShrink = 0.8,
  min_alpha = 1e-10,
  convergence_error = 1e-07,
  alpha = 0.5,
  alpha_g = 0.5,
  a1 = 3.7,
  a2 = 3,
  kernel = "gaussian",
  penalty = "L12",
  penalty_g = "L1",
  kernel_g = "gaussian",
  a1_g = 3.7,
  a2_g = 3,
  trend_g = "monotone",
  gamma_start_input = NULL,
  gamma_start_default = "zeros",
  max_iter_g = 10000,
  delta_g = 1e-05,
  max_alpha_g = 10000,
  stepsizeShrink_g = 0.8,
  min_alpha_g = 1e-12,
  convergence_error_g = 1e-07,
  run_aauc = FALSE
)
}
\arguments{
\item{n}{number of esperiments. Default is 1000}

\item{rows_train}{number of rows of the training sample. Default is 50,
for an high-dimensional setting}

\item{rows_test}{number of rows of the test sample. Default is 1000.
We suggest to create a test sample much bigger than the training sample
to test your method/model on more data}

\item{cols}{number of regressor variables of both the training and the
test samples. Default is 2000, for an high-dimensional setting}

\item{cols_cov}{number of covariate variables of both the training and the
test samples. Default is 20, increase it for an high-dimensional setting}

\item{covar}{covariance in the covariace matrix of the normal distribution.
Increasing it, the created features are more correlated. Default is 0.5}

\item{mu}{mean of the (multivariate) normal distribution of the regressors.
Default is 0}

\item{mu_cov}{mean of the (multivariate) normal distribution of the
covariates. Default is 0}

\item{lambda}{the penalization parameter of the regressors X}

\item{tau}{the penalization parameter of the covariates C, in covYI. Default 0,
i.e. no penalization term}

\item{trace}{2:visualize all the steps, 1:visualize just the result,
0:visualize nothing. Default is 1}

\item{used_cores}{number of core used for the parallelization of the
process. if equal to 1, then no parallelization is adopted. Default is 1.}

\item{c_function_of_covariates}{if TRUE, covYI is used to estimate the
cut-off point as function of the convariate information. If FALSE, the
covariate information is ignored. Default is FALSE}

\item{c_zero_fixed}{if TRUE the estimation process considers c, the cut-off
point, as fixed and equal to zero, to reduce the complexity of the estimation.
If FALSE c can vary and be different from zero, estimated by pye. Default
is FALSE}

\item{beta_start_input}{vector of a specific starting point for betas.
Default is NULL, i.e. no input vector}

\item{beta_start_default}{set the default starting point of betas. If
"zeros", it starts with a vector of all zeros, if "corr" it starts with the
value of the correlation of every regressor with the target variable y.
Default is "zeros"}

\item{max_iter}{maximum number of iterations in the algorithms mmAPG and
mnmAPG. Default is 500}

\item{trend}{if "monotone", mmAPG is used, if "nonmonotone", mnmAPG is used.
Default is "monotone"}

\item{delta}{parameter for the convergence condition of the optimization
algorithm. Default is 1e-5}

\item{max_alpha}{maximum value of the step-parameter alpha. Default is 1000}

\item{stepsizeShrink}{parameter to adjust the step-size in the backtracking
line-search, in the optimization of pye. Taking values between 0 and 1,
the closer to 1, the more accurate the estimation will be, the longer it
will take and viceversa. Default is 0.8}

\item{min_alpha}{minimum value of the step-parameter alpha. Default is 1e-12}

\item{convergence_error}{error to accept for considering the algorithm
converged. Default is 1e-5}

\item{alpha}{parameter for the Elastic-Net penalization term. Default is 0.5}

\item{alpha_g}{parameter for the Elastic-Net penalization term in covYI.
Default is 0.5}

\item{a1}{parameter for the SCAD and MCP penalization term. Default is 3.7}

\item{a2}{parameter for the MCP penalization term. Default is 3.0}

\item{kernel}{the kernel type to use for the estimation of the density
function (tested only for "gaussian").  Default is "gaussian"}

\item{penalty}{the considered penalty. To be chosen among L12, L1, EN, SCAD
and MCP. Default is "L1"}

\item{penalty_g}{the considered penalty of covYI. To be chosen among L12, L1,
EN, SCAD and MCP. Default if "L1"}

\item{kernel_g}{the kernel type to use for the estimation of the density
function (tested only for "gaussian") in covYI.  Default is "gaussian"}

\item{a1_g}{parameter for the SCAD and MCP penalization term in covYI. Default is 3.7}

\item{a2_g}{parameter for the MCP penalization term in covYI. Default is 3.0}

\item{trend_g}{for covYI. If "monotone", mmAPG is used, if "nonmonotone",
mnmAPG is used. Default is "monotone"}

\item{gamma_start_input}{vector of a specific starting point for gammas.
Default is NULL, i.e. no input vector}

\item{gamma_start_default}{set the default starting point of gamma.
If "zeros", it starts with all zero values, if "corr" it starts with the
value of the correlation of every regressor with the target variable. Default
is "zeros"}

\item{max_iter_g}{maximum number of iterations in the algorithms mmAPG and
mnmAPG in covYI. Default is 500}

\item{delta_g}{parameter for the convergence condition of the optimization
algorithm of covYI. Default is 1e-5}

\item{max_alpha_g}{maximum value of the step-parameter alpha in covYI.
Default is 100}

\item{stepsizeShrink_g}{parameter to adjust the step-size in the backtracking
line-search, in the optimization of covYI. Taking values between 0 and 1,
the closer to 1, the more accurate the estimation will be, the longer it
will take and viceversa. Default is 0.8}

\item{min_alpha_g}{minimum value of the step-parameter alpha in covYI.
Default is 1e-12}

\item{convergence_error_g}{in covYI, it is error to accept for considering the algorithm
converged. Default is 1e-5}

\item{run_aauc}{if FALSE the aAUC and aYI are not computed, to save stimation
time if not requested. Default is FALSE}
}
\value{
a list containing the classification measure related to every simulation.
}
\description{
function to perform the simulation on n different
experiments, for all the considered penalties of pye for simulated data.
In every iteration we start creating a new synthetic dataset and
then we randomly split it in train and test, estimating pye in the
train and evaluating the classification measures on the test set.
}
\examples{
library(pye)
rows_train <- 50
rows_test <- 1000
cols <- 2000
cols_cov <- 20
covar <- 0.5
mu <- rep(0,cols)
mu_cov <- rep(0,cols_cov)
pye_starting_point <- "zeros" #c("zeros", "corr")
alpha <- 0.5
used_cores <- 1
used_penalty_pye <- c("L1") #c("L12", "L1", "EN", "SCAD", "MCP")
measures_pye <- c("ccr") #c("auc", "aauc", "aYI", "ccr", "yi", "gm", "pye")
n<- 5 #number of simulations
c_function_of_covariates <- TRUE
trend <- "monotone" #or "nonmonotone"
c_zero_fixed <- FALSE

cat("This simulation is on with algorithm: ", trend, "and is c fixed: ", c_zero_fixed, "\n")

#--------------------------------------------------------------------------
#                                  START                                  |
#--------------------------------------------------------------------------
#pye Gaussian Kernel Smooth + covYI
for (p in used_penalty_pye){
  for (mm in 1:length(measures_pye)){
    cat("---> Starting with measure", measures_pye[mm], ", for the penalty", p, "<---\n")
    name <- paste0("PYE_KS_covYI_", p ,"_sim_study_", measures_pye[mm])
    lambda_to_use <- 0.1
    tau_to_use <- 0.05
    assign(name, PYE_simulation_study_synthetic_data(n=n, rows_train=rows_train,
							rows_test=rows_test,  cols=cols,
							cols_cov=cols_cov, covar=covar,
							mu=mu, mu_cov=mu_cov,
                             lambda=lambda_to_use,
                             tau=tau_to_use,
                             trend=trend,
                             beta_start_default=pye_starting_point,
                             gamma_start_default=pye_starting_point,
                             trace=1,
                             alpha=alpha, alpha_g=alpha,
                             a1=3.7, a2=3.7,
                             a1_g=3.7, a2_g=3.7,
                             penalty=p, penalty_g=p,
                             kernel="gaussian", used_cores=used_cores,
                             c_function_of_covariates=c_function_of_covariates,
							c_zero_fixed=c_zero_fixed,
								run_aauc=FALSE,
								max_iter=10, max_iter_g=10))
  }
}
cat("Computation finished! Start saving data.")
print(name)

}
